{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import sys; sys.argv=['']; del sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sepcify parameters **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.005, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--decay', type=float, default=0.00001, metavar='LR',\n",
    "                    help='learning rate (default: 0.00001)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "help='how many batches to wait before logging training status')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define Model and Optimizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from vgg import *\n",
    "\n",
    "model = VGG('VGG19')\n",
    "arch = 'VGG19'\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define optimizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load pre-trained model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models/model_best_99.38.pkl'\n",
      "=> loaded checkpoint 'models/model_best_99.38.pkl' (epoch 30) (accuracy 99.3796114274)\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/model_best_99.38.pkl'\n",
    "\n",
    "print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "checkpoint = torch.load(model_path)\n",
    "args.start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(\"=> loaded checkpoint '{}' (epoch {}) (accuracy {})\"\n",
    "      .format(model_path, checkpoint['epoch'], checkpoint['best_prec1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Implement CRF post processing **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import matplotlib.pylab as plt\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from pydensecrf.utils import softmax_to_unary\n",
    "\n",
    "\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n",
    "    create_pairwise_gaussian\n",
    "    \n",
    "def crf_postprocess(image,seg_mask,use_2d):    \n",
    "    \n",
    "    (x,y) = np.nonzero(np.sum(image!=15,axis=2))\n",
    "    top_left_x, top_left_y = x[0],y[0]\n",
    "    bottom_right_x, bottom_right_y = x[-1],y[-1]\n",
    "\n",
    "    img = image[top_left_x:bottom_right_x,top_left_y:bottom_right_y,:]\n",
    "    mask = seg_mask[top_left_x:bottom_right_x,top_left_y:bottom_right_y]\n",
    "    \n",
    "    # img = image[0].transpose((1,2,0))\n",
    "    labels = relabel_sequential(mask)[0].flatten().astype('uint8') + 1\n",
    "\n",
    "\n",
    "    M = 21 # 21 Classes to match the C++ example\n",
    "\n",
    "    # Example using the DenseCRF class and the util functions\n",
    "    d = dcrf.DenseCRF(img.shape[0] * img.shape[1], M)\n",
    "    \n",
    "    # get unary potentials (neg log probability)\n",
    "    U = compute_unary(labels, M, GT_PROB=0.5)\n",
    "    d.setUnaryEnergy(U)\n",
    "\n",
    "    # This creates the color-independent features and then add them to the CRF\n",
    "    feats = create_pairwise_gaussian(sdims=(23, 23), shape=img.shape[:2])\n",
    "    d.addPairwiseEnergy(feats, compat=3,\n",
    "                        kernel=dcrf.DIAG_KERNEL,\n",
    "                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    # This creates the color-dependent features and then add them to the CRF\n",
    "    feats = create_pairwise_bilateral(sdims=(100, 100), schan=(5, 5, 5),\n",
    "                                      img=img, chdim=2)\n",
    "    d.addPairwiseEnergy(feats, compat=10,\n",
    "                        kernel=dcrf.DIAG_KERNEL,\n",
    "                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    Q = d.inference(20)\n",
    "    map = np.argmax(Q, axis=0).reshape(img.shape[:2])\n",
    "\n",
    "    res = (map.astype('float32') * 255 / map.max() > 0).astype('float32')\n",
    "   \n",
    "    crf_mask = np.zeros((image.shape[:2]))\n",
    "    crf_mask[top_left_x:bottom_right_x,top_left_y:bottom_right_y] = res\n",
    "\n",
    "    crf_seg_img = np.multiply(image,np.transpose(np.tile(crf_mask,(3,1,1)),(1,2,0))).astype('uint8')\n",
    "    \n",
    "    return (crf_mask,crf_seg_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pydensecrf.compute_unary is deprecated, use unary_from_labels instead.\n"
     ]
    }
   ],
   "source": [
    "box_side = 50\n",
    "directory   = '../../Data/Test/Images'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".png\"): \n",
    "        img_path = os.path.join(directory, filename)\n",
    "        image = np.asarray(Image.open(img_path))\n",
    "        seg_mask,seg_img = get_predict(model,image,box_side)\n",
    "        \n",
    "        crf_mask,crf_seg_img = crf_postprocess(image,seg_mask,False)\n",
    "        \n",
    "        print('Segmented image {}'.format(filename))\n",
    "        \n",
    "        break\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
